{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Загрузите выборку из файла gbm-data.csv с помощью pandas и преобразуйте ее в массив numpy (параметр values у датафрейма). \n",
    "# В первой колонке файла с данными записано, была или нет реакция. \n",
    "# Все остальные колонки (d1 - d1776) содержат различные характеристики молекулы, такие как размер, форма и т.д. \n",
    "# Разбейте выборку на обучающую и тестовую,используя функцию train_test_split с параметрами test_size = 0.8 и random_state = 241."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('gbm-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3751"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data) # размер матрицы = 3751 х 1777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497009</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.273166</td>\n",
       "      <td>0.585445</td>\n",
       "      <td>0.743663</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.606291</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.803455</td>\n",
       "      <td>0.106105</td>\n",
       "      <td>0.411754</td>\n",
       "      <td>0.836582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.480124</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209791</td>\n",
       "      <td>0.610350</td>\n",
       "      <td>0.356453</td>\n",
       "      <td>0.517720</td>\n",
       "      <td>0.679051</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.196344</td>\n",
       "      <td>0.724230</td>\n",
       "      <td>0.235606</td>\n",
       "      <td>0.288764</td>\n",
       "      <td>0.805110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.517794</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494734</td>\n",
       "      <td>0.781422</td>\n",
       "      <td>0.154361</td>\n",
       "      <td>0.303809</td>\n",
       "      <td>0.812646</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
       "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
       "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
       "2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n",
       "3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n",
       "4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n",
       "\n",
       "         D8        D9  ...    D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
       "0  0.585445  0.743663  ...        0      0      0      0      0      0      0   \n",
       "1  0.411754  0.836582  ...        1      1      1      1      0      1      0   \n",
       "2  0.517720  0.679051  ...        0      0      0      0      0      0      0   \n",
       "3  0.288764  0.805110  ...        0      0      0      0      0      0      0   \n",
       "4  0.303809  0.812646  ...        0      0      0      0      0      0      0   \n",
       "\n",
       "   D1774  D1775  D1776  \n",
       "0      0      0      0  \n",
       "1      0      1      0  \n",
       "2      0      0      0  \n",
       "3      0      0      0  \n",
       "4      0      0      0  \n",
       "\n",
       "[5 rows x 1777 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = data.loc[:, 'D1':'D1776']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data.iloc[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.8, random_state=241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обучите GradientBoostingClassifier с параметрами n_estimators=250, verbose=True, random_state=241 \n",
    "# и для каждого значения learning_rate из списка [1, 0.5, 0.3, 0.2, 0.1] проделайте следующее:\n",
    "#   - Используйте метод staged_decision_function для предсказания качества на обучающей и тестовой выборке на каждой итерации.\n",
    "#   - Преобразуйте полученное предсказание с помощью сигмоидной функции по формуле 1 / (1 + e^{−y_pred}), \n",
    "#     где y_pred — предсказанное значение.\n",
    "#   - Вычислите и постройте график значений log-loss (которую можно посчитать с помощью функции sklearn.metrics.log_loss) \n",
    "# на обучающей и тестовой выборках, а также найдите минимальное значение метрики и номер итерации, на которой оно достигается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(y_pred):\n",
    "    # Преобразуйте полученное предсказание с помощью сигмоидной функции по формуле 1 / (1 + e^{−y_pred}),\n",
    "    # где y_pred — предсказаное значение.\n",
    "    return 1.0 / (1.0 + math.exp(-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "for learning_rate in [1, 0.5, 0.3, 0.2, 0.1]:\n",
    "    clf = GradientBoostingClassifier(learning_rate=learning_rate, n_estimators=250, verbose=True, random_state=241)\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    train_loss = []\n",
    "    for pred in clf.staged_decision_function(x_train):\n",
    "           train_loss.append(log_loss(y_train, [sigmoid(y_pred) for y_pred in pred]))\n",
    "    \n",
    "    test_loss = []\n",
    "    for pred in clf.staged_decision_function(x_test):\n",
    "           test_loss.append(log_loss(y_test, [sigmoid(y_pred) for y_pred in pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAELCAYAAAA2mZrgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREQkl5KCiIjk+v8/otCGAKnkvgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115ba7d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(train_loss, 'b', linewidth=2)\n",
    "plt.plot(test_loss, 'r', linewidth=2)\n",
    "plt.legend(['train_loss', 'test_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_loss_train = min(train_loss)\n",
    "min_loss_test= min(test_loss)\n",
    "min_loss_index1 = train_loss.index(min_loss_train)\n",
    "min_loss_index2 = test_loss.index(min_loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.089369624162740857, 249)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_loss_train, min_loss_index1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.52692018722758438, 51)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_loss_test, min_loss_index2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. Как можно охарактеризовать график качества на тестовой выборке, начиная с некоторой итерации: \n",
    "# переобучение (overfitting) или недообучение (underfitting)? В ответе укажите одно из слов overfitting либо underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ответ: overfitting, т.к. функция потерь на обучающей выборке принимает значение менее 1%, \n",
    "# зато на тестовой выборке значение функции потерь превышает 50%, \n",
    "# что говорит нам о том, что алгоритм работает хуже, чем константный метод. что является сдедствием его переобучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. Приведите минимальное значение log-loss на тестовой выборке и номер итерации, на котором оно достигается, \n",
    "# при learning_rate = 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2613           13.80s\n",
      "         2           1.1715           14.35s\n",
      "         3           1.1009           14.01s\n",
      "         4           1.0529           15.00s\n",
      "         5           1.0130           14.94s\n",
      "         6           0.9740           14.58s\n",
      "         7           0.9475           13.51s\n",
      "         8           0.9197           13.55s\n",
      "         9           0.8979           13.03s\n",
      "        10           0.8730           12.97s\n",
      "        20           0.7207           10.43s\n",
      "        30           0.6055            9.59s\n",
      "        40           0.5244            8.77s\n",
      "        50           0.4501            8.24s\n",
      "        60           0.3908            7.94s\n",
      "        70           0.3372            7.65s\n",
      "        80           0.3009            7.19s\n",
      "        90           0.2603            6.85s\n",
      "       100           0.2327            6.46s\n",
      "       200           0.0835            2.14s\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate=0.2, n_estimators=250, verbose=True, random_state=241)\n",
    "clf.fit(x_train, y_train)\n",
    "     \n",
    "test_loss = []\n",
    "for pred in clf.staged_decision_function(x_test):\n",
    "    test_loss.append(log_loss(y_test, [sigmoid(y_pred) for y_pred in pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_loss_test= min(test_loss)\n",
    "min_loss_index = test_loss.index(min_loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53 36\n"
     ]
    }
   ],
   "source": [
    "print('{:0.2f} {}'.format(min_loss_test,min_loss_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5. На этих же данных обучите RandomForestClassifier с количеством деревьев, равным количеству итераций, \n",
    "# на котором достигается наилучшее качество у градиентного бустинга из предыдущего пункта, \n",
    "# c random_state=241 и остальными параметрами по умолчанию. \n",
    "# Какое значение log-loss на тесте получается у этого случайного леса? \n",
    "# (Не забывайте, что предсказания нужно получать с помощью функции predict_proba. \n",
    "# В данном случае брать сигмоиду от оценки вероятности класса не нужно)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=min_loss_index, random_state=241)\n",
    "rfc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = rfc.predict_proba(x_test)[:, 1]\n",
    "test_loss = log_loss(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54\n"
     ]
    }
   ],
   "source": [
    "print('{:0.2f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
